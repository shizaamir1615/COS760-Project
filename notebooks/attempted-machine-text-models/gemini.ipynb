# Step 1: Install Required Libraries
!pip install datasets transformers langid pandas tqdm openai --quiet

# Step 2: Clone and Load Aligned Vuk'uzenzele Data
import os
import pandas as pd

!git clone https://github.com/dsfsi/vukuzenzele-nlp.git || echo "Repo already cloned."

data_dir = "vukuzenzele-nlp/data/sentence_align_output"
desired_langs = ['ven', 'xho', 'nso', 'tso']
data = []

csv_files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]
for file in csv_files:
    langs = file.split("_")[1].split(".")[0].split("_")
    if any(lang in desired_langs for lang in langs):
        try:
            df = pd.read_csv(os.path.join(data_dir, file))
            df["src_lang"] = langs[0]
            df["tgt_lang"] = langs[1] if len(langs) > 1 else langs[0]
            df = df[["src_text", "tgt_text", "cosine_score", "src_lang", "tgt_lang"]]
            data.append(df)
        except Exception as e:
            print(f"Error in {file}: {e}")

df = pd.concat(data, ignore_index=True)

# Step 3: Filter Human Texts
languages = ['ven', 'xho', 'nso', 'tso']
filtered = df[df['src_lang'].isin(languages)].copy()
filtered['language'] = filtered['src_lang']
filtered['type'] = 'human_text'

# Step 4: Prepare Gemini-style Prompts
PROMPTS = {
    "ven": ["Write a short official government message in Venda language about healthcare services."],
    "xho": ["Write a short official government message in isiXhosa language about public healthcare."],
    "nso": ["Write a short official government message in Northern Sotho about education policies."],
    "tso": ["Write a short official government message in Tsonga about government services."],
}

# Step 5: Setup OpenAI API (simulate Gemini-style generation)
import openai

openai.api_key = "YOUR_OPENAI_API_KEY"  # Replace with your key

from tqdm.notebook import tqdm
import random
import langid

results = []
max_per_lang = 200

for lang in languages:
    print(f"Generating for '{lang}'")
    count = 0
    seen_texts = set()
    pbar = tqdm(total=max_per_lang, desc=f"{lang.upper()} Progress")

    while count < max_per_lang:
        prompt = random.choice(PROMPTS[lang])
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are generating realistic civic government messages in multiple African languages for language modeling."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.9,
                max_tokens=120
            )
            gen_text = response.choices[0].message.content.strip()

            if (
                gen_text and
                12 <= len(gen_text.split()) <= 40 and
                langid.classify(gen_text)[0] == lang and
                gen_text not in seen_texts
            ):
                results.append({
                    "src_text": gen_text,
                    "label": 1,
                    "language": lang
                })
                seen_texts.add(gen_text)
                count += 1
                pbar.update(1)
        except Exception as e:
            print(f"Error: {e}")
            continue

    pbar.close()

# Step 6: Save Dataset
machine_df = pd.DataFrame(results)
human_df = filtered[['src_text', 'language']]
human_df['label'] = 0

final_df = pd.concat([human_df, machine_df], ignore_index=True)
final_df = final_df.sample(frac=1, random_state=42)

final_df.to_csv("vukuzenzele_labeled_gemini.csv", index=False)
print("Final dataset saved to 'vukuzenzele_labeled_gemini.csv'")
